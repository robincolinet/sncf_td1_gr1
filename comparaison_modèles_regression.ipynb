{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.multioutput import RegressorChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_data, creer_feature_ligne, creer_features_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "creer_features_date(data)\n",
    "creer_feature_ligne(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost pour prédire seulement le retard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    # Éviter de diviser par zéro\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 60 is smaller than n_iter=100. Running 60 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 300 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n260 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 171, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 1168, in _boost\n    estimator.fit(X_, y_)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n    super()._fit(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 242, in _fit\n    X, y = self._validate_data(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 617, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'National'\n\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 171, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 1168, in _boost\n    estimator.fit(X_, y_)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n    super()._fit(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 242, in _fit\n    X, y = self._validate_data(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 617, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'International'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Utilisation de RandomizedSearchCV pour optimiser les hyperparamètres\u001b[39;00m\n\u001b[1;32m     17\u001b[0m ada_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(ada, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid_ada, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mada_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Meilleurs hyperparamètres pour AdaBoost\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(ada_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1810\u001b[0m         ParameterSampler(\n\u001b[1;32m   1811\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1812\u001b[0m         )\n\u001b[1;32m   1813\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 300 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n260 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 171, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 1168, in _boost\n    estimator.fit(X_, y_)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n    super()._fit(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 242, in _fit\n    X, y = self._validate_data(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 617, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'National'\n\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 171, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\", line 1168, in _boost\n    estimator.fit(X_, y_)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n    super()._fit(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 242, in _fit\n    X, y = self._validate_data(\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 617, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'International'\n"
     ]
    }
   ],
   "source": [
    "X = data[['service', 'gare_depart', 'gare_arrivee', 'duree_moyenne', 'nb_train_prevu', 'ligne', 'mois']]\n",
    "y = data['retard_moyen_arrivee']\n",
    "\n",
    "X = pd.get_dummies(X, columns=['gare_depart', 'gare_arrivee', 'service', 'ligne'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialisation de l'estimateur AdaBoost\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "# Grille d'hyperparamètres pour AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "# Utilisation de RandomizedSearchCV pour optimiser les hyperparamètres\n",
    "ada_search = RandomizedSearchCV(ada, param_distributions=param_grid_ada, n_iter=100, cv=5, verbose=0, n_jobs=-1, random_state=42)\n",
    "ada_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres pour AdaBoost\n",
    "print(ada_search.best_params_)\n",
    "\n",
    "# Prédiction avec le modèle AdaBoost optimisé\n",
    "y_pred_ada = ada_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Métriques d'évaluation pour AdaBoost\n",
    "mae_ada = mean_absolute_error(y_test, y_pred_ada)\n",
    "mse_ada = mean_squared_error(y_test, y_pred_ada)\n",
    "mape_ada = mean_absolute_percentage_error(y_test, y_pred_ada)\n",
    "r2_ada = r2_score(y_test, y_pred_ada)\n",
    "\n",
    "print(f\"Mean Squared Error with AdaBoost: {mse_ada}\")\n",
    "print(f\"Mean Absolute Error with AdaBoost: {mae_ada}\")\n",
    "print(f\"Mean Absolute Percentage Error with AdaBoost: {mape_ada}\")\n",
    "print(f\"R2 Score with AdaBoost: {r2_ada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest avec hyperparamètres optimisés par Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cibles = ['retard_moyen_arrivee','prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic',\n",
    "       'prct_cause_materiel_roulant', 'prct_cause_gestion_gare',\n",
    "       'prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "X = data[['service', 'gare_depart', 'gare_arrivee', 'duree_moyenne', 'nb_train_prevu', 'ligne', 'mois']]\n",
    "y = data[cibles]\n",
    "\n",
    "# One-Hot Encoding pour les colonnes catégorielles\n",
    "X = pd.get_dummies(X, columns=['gare_depart', 'gare_arrivee', 'service', 'ligne'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres : \n",
      " {'n_estimators': 200, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': True}\n",
      "--- retard_moyen_arrivee ---\n",
      "Mean Squared Error with RandomizedSearch: 190.137032287581\n",
      "Mean Absolute Error with RandomizedSearch: 8.528909205936626\n",
      "R2 Score with RandomizedSearch: 0.2971565156153778\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 25.527466405610806\n",
      "--- prct_cause_externe ---\n",
      "Mean Squared Error with RandomizedSearch: 266.3162264626453\n",
      "Mean Absolute Error with RandomizedSearch: 12.055815350692363\n",
      "R2 Score with RandomizedSearch: 0.0661996488484623\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 58.897889571496144\n",
      "--- prct_cause_infra ---\n",
      "Mean Squared Error with RandomizedSearch: 215.21500414969813\n",
      "Mean Absolute Error with RandomizedSearch: 10.859101292788978\n",
      "R2 Score with RandomizedSearch: 0.15498599642350386\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 54.149124143019634\n",
      "--- prct_cause_gestion_trafic ---\n",
      "Mean Squared Error with RandomizedSearch: 186.50258391464118\n",
      "Mean Absolute Error with RandomizedSearch: 10.051112329537773\n",
      "R2 Score with RandomizedSearch: 0.16777793220651438\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 55.28221573331928\n",
      "--- prct_cause_materiel_roulant ---\n",
      "Mean Squared Error with RandomizedSearch: 158.4140041888004\n",
      "Mean Absolute Error with RandomizedSearch: 9.021223319903212\n",
      "R2 Score with RandomizedSearch: 0.19655474516694682\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 49.07935127501061\n",
      "--- prct_cause_gestion_gare ---\n",
      "Mean Squared Error with RandomizedSearch: 58.758341011258715\n",
      "Mean Absolute Error with RandomizedSearch: 5.146284716304154\n",
      "R2 Score with RandomizedSearch: 0.09301974743165453\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 56.49207943500434\n",
      "--- prct_cause_prise_en_charge_voyageurs ---\n",
      "Mean Squared Error with RandomizedSearch: 91.97245094105837\n",
      "Mean Absolute Error with RandomizedSearch: 6.134082909972192\n",
      "R2 Score with RandomizedSearch: 0.1653667177989172\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 71.09954374503768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_30340\\3806477984.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  y_pred_normalized = 100 * y_pred_cause / sums\n"
     ]
    }
   ],
   "source": [
    "param_grid_randomized = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 5, 10, 20, 50, 75],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "# Recherche aléatoire avec validation croisée\n",
    "rf_search = RandomizedSearchCV(rf, param_distributions=param_grid_randomized, n_iter=100, cv=5, verbose=0, n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres\n",
    "print(\"Meilleurs paramètres : \\n\",rf_search.best_params_)\n",
    "\n",
    "#y_pred_grid = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_randomized = rf_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Séparation des prédictions de retard_moyen_arrivee\n",
    "y_pred_retard = y_pred_randomized[:, 0]\n",
    "\n",
    "# Prédictions pour les autres colonnes\n",
    "y_pred_cause = y_pred_randomized[:, 1:]\n",
    "\n",
    "# Normalisation de ces prédictions pour qu'elles somment à 100\n",
    "sums = y_pred_cause.sum(axis=1)[:, np.newaxis]\n",
    "y_pred_normalized = 100 * y_pred_cause / sums\n",
    "\n",
    "# Ajout des prédictions de retard_moyen_arrivee aux prédictions normalisées\n",
    "y_pred_final = np.hstack([y_pred_retard[:, np.newaxis], y_pred_normalized])\n",
    "\n",
    "for i, cible in enumerate(cibles):\n",
    "\n",
    "    mask1 = ~np.isnan(y_test[cible])\n",
    "    mask2 = ~np.isnan(y_pred_final[:, i])\n",
    "\n",
    "    mask = mask1 & mask2\n",
    "    # Appliquez le masque aux prédictions et aux vraies valeurs\n",
    "    y_test_non_nan = y_test[cible][mask]\n",
    "    y_pred_non_nan = y_pred_final[:, i][mask]\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_non_nan, y_pred_non_nan)\n",
    "    mse_randomized = mean_squared_error(y_test_non_nan, y_pred_non_nan)\n",
    "    \n",
    "    r2 = r2_score(y_test_non_nan, y_pred_non_nan)\n",
    "    \n",
    "    print(f\"--- {cible} ---\")\n",
    "    print(f\"RMSE with RandomizedSearch: {mse_randomized**0.5}\")\n",
    "    print(f\"Mean Absolute Error with RandomizedSearch: {mae}\")\n",
    "    print(f\"R2 Score with RandomizedSearch: {r2}\")\n",
    "\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(y_test_non_nan, y_pred_non_nan)\n",
    "        print(f\"Mean Absolute Percentage Error with RandomizedSearch: {mape}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params =  {'n_estimators': 200, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- retard_moyen_arrivee ---\n",
      "Mean Squared Error with RandomizedSearch: 191.96895812609822\n",
      "Mean Absolute Error with RandomizedSearch: 8.512087665825414\n",
      "R2 Score with RandomizedSearch: 0.2903847830181727\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 25.29525419961754\n",
      "--- prct_cause_externe ---\n",
      "Mean Squared Error with RandomizedSearch: 263.4552565548811\n",
      "Mean Absolute Error with RandomizedSearch: 11.945304050631787\n",
      "R2 Score with RandomizedSearch: 0.08180655812255744\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 60.69934231543236\n",
      "--- prct_cause_infra ---\n",
      "Mean Squared Error with RandomizedSearch: 223.71905422212123\n",
      "Mean Absolute Error with RandomizedSearch: 10.985230068221963\n",
      "R2 Score with RandomizedSearch: 0.1269851175023624\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 54.366974229414545\n",
      "--- prct_cause_gestion_trafic ---\n",
      "Mean Squared Error with RandomizedSearch: 197.7841740564105\n",
      "Mean Absolute Error with RandomizedSearch: 10.360090091613515\n",
      "R2 Score with RandomizedSearch: 0.12137445409328929\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 57.83680149324755\n",
      "--- prct_cause_materiel_roulant ---\n",
      "Mean Squared Error with RandomizedSearch: 169.24733152467533\n",
      "Mean Absolute Error with RandomizedSearch: 9.236243292305607\n",
      "R2 Score with RandomizedSearch: 0.1457623956705767\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 52.18538528184725\n",
      "--- prct_cause_gestion_gare ---\n",
      "Mean Squared Error with RandomizedSearch: 91.71288394188441\n",
      "Mean Absolute Error with RandomizedSearch: 5.793430336002416\n",
      "R2 Score with RandomizedSearch: -0.4189507980797118\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 59.03255803845301\n",
      "--- prct_cause_prise_en_charge_voyageurs ---\n",
      "Mean Squared Error with RandomizedSearch: 120.83575972641292\n",
      "Mean Absolute Error with RandomizedSearch: 6.577653042231196\n",
      "R2 Score with RandomizedSearch: -0.10040187523871902\n",
      "Mean Absolute Percentage Error with RandomizedSearch: 72.45114696190467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_30340\\2521799734.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  y_pred_normalized = 100 * y_pred_cause / sums\n"
     ]
    }
   ],
   "source": [
    "best_rf = rf_search.best_estimator_ \n",
    "\n",
    "# Utilisation du modèle optimisé dans RegressorChain\n",
    "chain_rf = RegressorChain(best_rf)\n",
    "chain_rf.fit(X_train, y_train)\n",
    "y_pred_chain = chain_rf.predict(X_test)\n",
    "\n",
    "# Séparation des prédictions de retard_moyen_arrivee\n",
    "y_pred_retard = y_pred_chain[:, 0]\n",
    "\n",
    "# Prédictions pour les autres colonnes\n",
    "y_pred_cause = y_pred_chain[:, 1:]\n",
    "\n",
    "# Normalisation de ces prédictions pour qu'elles somment à 100\n",
    "sums = y_pred_cause.sum(axis=1)[:, np.newaxis]\n",
    "y_pred_normalized = 100 * y_pred_cause / sums\n",
    "\n",
    "# Ajout des prédictions de retard_moyen_arrivee aux prédictions normalisées\n",
    "y_pred_final = np.hstack([y_pred_retard[:, np.newaxis], y_pred_normalized])\n",
    "\n",
    "for i, cible in enumerate(cibles):\n",
    "\n",
    "    mask1 = ~np.isnan(y_test[cible])\n",
    "    mask2 = ~np.isnan(y_pred_final[:, i])\n",
    "\n",
    "    mask = mask1 & mask2\n",
    "    # Appliquez le masque aux prédictions et aux vraies valeurs\n",
    "    y_test_non_nan = y_test[cible][mask]\n",
    "    y_pred_non_nan = y_pred_final[:, i][mask]\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_non_nan, y_pred_non_nan)\n",
    "    mse_randomized = mean_squared_error(y_test_non_nan, y_pred_non_nan)\n",
    "    \n",
    "    r2 = r2_score(y_test_non_nan, y_pred_non_nan)\n",
    "    \n",
    "    print(f\"--- {cible} ---\")\n",
    "    print(f\"RMSE with RandomizedSearch: {mse_randomized**0.5}\")\n",
    "    print(f\"Mean Absolute Error with RandomizedSearch: {mae}\")\n",
    "    print(f\"R2 Score with RandomizedSearch: {r2}\")\n",
    "\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(y_test_non_nan, y_pred_non_nan)\n",
    "        print(f\"Mean Absolute Percentage Error with RandomizedSearch: {mape}\")\n",
    "    except:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5647cfce6fa2861c5d5993eed494c4303d5a706b1125d41555b49a965ed01245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
