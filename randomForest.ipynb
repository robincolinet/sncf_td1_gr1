{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_data, creer_feature_ligne, preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import RegressorChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    # Éviter de diviser par zéro\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "preprocess_data(data)\n",
    "creer_feature_ligne(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plusieurs clusterings + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cibles = ['retard_moyen_arrivee','prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic',\n",
    "       'prct_cause_materiel_roulant', 'prct_cause_gestion_gare',\n",
    "       'prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "X = data[['service', 'gare_depart', 'gare_arrivee', 'duree_moyenne', 'nb_train_prevu', 'ligne', 'mois']]\n",
    "y = data[cibles]\n",
    "\n",
    "# One-Hot Encoding pour les colonnes catégorielles\n",
    "X = pd.get_dummies(X, columns=['gare_depart', 'gare_arrivee', 'service', 'ligne'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Ajout d'une feature en utilisant un clustering\n",
    "\n",
    "# One-Hot Encoding pour les colonnes catégorielles\n",
    "#X_cluster = pd.get_dummies(df, columns=['date','gare_depart', 'gare_arrivee', 'service', 'ligne'])\n",
    "#X_cluster = X_cluster.drop(['commentaire_annulation', 'commentaire_retards_depart', 'commentaires_retard_arrivee'], axis=1)\n",
    "\n",
    "#Trouvé à l'aide de l'elbow méthode\n",
    "k_optimal = 3\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42)\n",
    "#df['cluster'] = kmeans.fit_predict(X_train)\n",
    "\n",
    "#majority_class = {}\n",
    "#lignes= df['ligne'].unique()\n",
    "#for ligne in lignes:\n",
    "#    cluster_labels = df[df['ligne'] == ligne]['cluster'].tolist()\n",
    "#    majority_label = Counter(cluster_labels).most_common(1)[0][0]\n",
    "#    majority_class[ligne] = majority_label\n",
    "\n",
    "\n",
    "#df['majority_class'] = df['ligne'].map(majority_class)\n",
    "\n",
    "X_train['cluster'] = kmeans.fit_predict(X_train)\n",
    "X_test['cluster'] = kmeans.predict(X_test)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 5, 10, 20, 50, 75],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "param_grid_multi_rf = {\n",
    "    'estimator__n_estimators': [10, 50, 100, 200],\n",
    "    'estimator__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "multi_rf = MultiOutputRegressor(rf)\n",
    "\n",
    "\n",
    "# Recherche aléatoire avec validation croisée\n",
    "rf_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=100, cv=5, verbose=0, n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres\n",
    "print(\"Meilleurs paramètres : \\n\",rf_search.best_params_)\n",
    "\n",
    "#y_pred_grid = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_randomized = rf_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Séparation des prédictions de retard_moyen_arrivee\n",
    "y_pred_retard = y_pred_randomized[:, 0]\n",
    "\n",
    "# Prédictions pour les autres colonnes\n",
    "y_pred_cause = y_pred_randomized[:, 1:]\n",
    "\n",
    "# Normalisation de ces prédictions pour qu'elles somment à 100\n",
    "sums = y_pred_cause.sum(axis=1)[:, np.newaxis]\n",
    "y_pred_normalized = 100 * y_pred_cause / sums\n",
    "\n",
    "# Ajout des prédictions de retard_moyen_arrivee aux prédictions normalisées\n",
    "y_pred_final = np.hstack([y_pred_retard[:, np.newaxis], y_pred_normalized])\n",
    "\n",
    "for i, cible in enumerate(cibles):\n",
    "    mae = mean_absolute_error(y_test[cible], y_pred_final[:, i])\n",
    "    mse_randomized = mean_squared_error(y_test[cible], y_pred_final[:, i])\n",
    "    mape = mean_absolute_percentage_error(y_test[cible], y_pred_final[:, i])\n",
    "    r2 = r2_score(y_test[cible], y_pred_final[:, i])\n",
    "    \n",
    "    print(f\"--- {cible} ---\")\n",
    "    print(f\"Mean Squared Error with RandomizedSearch: {mse_randomized}\")\n",
    "    print(f\"Mean Absolute Error with RandomizedSearch: {mae}\")\n",
    "    print(f\"Mean Absolute Percentage Error with RandomizedSearch: {mape}\")\n",
    "    print(f\"R2 Score with RandomizedSearch: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF optimisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error with RandomizedSearch: 8.6689234939845\n",
      "R2 Score with RandomizedSearch: 0.2804701547444919\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=50, min_samples_split=2, min_samples_leaf=4, max_features='sqrt', max_depth=None, bootstrap=True)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error with RandomizedSearch: {mae}\")\n",
    "print(f\"R2 Score with RandomizedSearch: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Différence ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_optimal = 3\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42)\n",
    "\n",
    "X_train['cluster'] = kmeans.fit_predict(X_train)\n",
    "X_test['cluster'] = kmeans.predict(X_test)\n",
    "rf = RandomForestRegressor()\n",
    "# multi_rf = MultiOutputRegressor(rf)\n",
    "\n",
    "# Recherche aléatoire avec validation croisée\n",
    "rf_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=100, cv=5, verbose=0, n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres\n",
    "print(\"Meilleurs paramètres : \\n\",rf_search.best_params_)\n",
    "\n",
    "y_pred_randomized = rf_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Séparation des prédictions de retard_moyen_arrivee\n",
    "y_pred_retard = y_pred_randomized[:, 0]\n",
    "\n",
    "# Prédictions pour les autres colonnes\n",
    "y_pred_cause = y_pred_randomized[:, 1:]\n",
    "\n",
    "# Normalisation de ces prédictions pour qu'elles somment à 100\n",
    "sums = y_pred_cause.sum(axis=1)[:, np.newaxis]\n",
    "y_pred_normalized = 100 * y_pred_cause / sums\n",
    "\n",
    "# Ajout des prédictions de retard_moyen_arrivee aux prédictions normalisées\n",
    "y_pred_final = np.hstack([y_pred_retard[:, np.newaxis], y_pred_normalized])\n",
    "\n",
    "for i, cible in enumerate(cibles):\n",
    "    mae = mean_absolute_error(y_test[cible], y_pred_final[:, i])\n",
    "    mse_randomized = mean_squared_error(y_test[cible], y_pred_final[:, i])\n",
    "    mape = mean_absolute_percentage_error(y_test[cible], y_pred_final[:, i])\n",
    "    r2 = r2_score(y_test[cible], y_pred_final[:, i])\n",
    "    \n",
    "    print(f\"--- {cible} ---\")\n",
    "    print(f\"Mean Squared Error with RandomizedSearch: {mse_randomized}\")\n",
    "    print(f\"Mean Absolute Error with RandomizedSearch: {mae}\")\n",
    "    print(f\"Mean Absolute Percentage Error with RandomizedSearch: {mape}\")\n",
    "    print(f\"R2 Score with RandomizedSearch: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- retard_moyen_arrivee ---\n",
      "Mean Squared Error with RegressorChain: 197.5415713502332\n",
      "Mean Absolute Error with RegressorChain: 8.668389372662315\n",
      "Mean Absolute Percentage Error with RegressorChain: 25.596084513701605\n",
      "R2 Score with RegressorChain: 0.26978556124397923\n",
      "--- prct_cause_externe ---\n",
      "Mean Squared Error with RegressorChain: 245.6393074708426\n",
      "Mean Absolute Error with RegressorChain: 11.732289238593191\n",
      "Mean Absolute Percentage Error with RegressorChain: 60.17115549653846\n",
      "R2 Score with RegressorChain: 0.14526801054073202\n",
      "--- prct_cause_infra ---\n",
      "Mean Squared Error with RegressorChain: 216.94093418809442\n",
      "Mean Absolute Error with RegressorChain: 10.879777551502835\n",
      "Mean Absolute Percentage Error with RegressorChain: 55.010910665651465\n",
      "R2 Score with RegressorChain: 0.1548119343672627\n",
      "--- prct_cause_gestion_trafic ---\n",
      "Mean Squared Error with RegressorChain: 182.444769503909\n",
      "Mean Absolute Error with RegressorChain: 10.078631272222765\n",
      "Mean Absolute Percentage Error with RegressorChain: 57.39324233355242\n",
      "R2 Score with RegressorChain: 0.19047284658187547\n",
      "--- prct_cause_materiel_roulant ---\n",
      "Mean Squared Error with RegressorChain: 156.17452340861965\n",
      "Mean Absolute Error with RegressorChain: 9.040228552992057\n",
      "Mean Absolute Percentage Error with RegressorChain: 50.447650197473806\n",
      "R2 Score with RegressorChain: 0.21275281713014393\n",
      "--- prct_cause_gestion_gare ---\n",
      "Mean Squared Error with RegressorChain: 59.2165822819143\n",
      "Mean Absolute Error with RegressorChain: 5.333469148251857\n",
      "Mean Absolute Percentage Error with RegressorChain: 56.37403053503783\n",
      "R2 Score with RegressorChain: 0.08323510088784258\n",
      "--- prct_cause_prise_en_charge_voyageurs ---\n",
      "Mean Squared Error with RegressorChain: 97.84976851606447\n",
      "Mean Absolute Error with RegressorChain: 6.239360484883746\n",
      "Mean Absolute Percentage Error with RegressorChain: 68.44942541163937\n",
      "R2 Score with RegressorChain: 0.1080709436866516\n"
     ]
    }
   ],
   "source": [
    "best_rf = rf_search.best_estimator_ \n",
    "\n",
    "# Utilisation du modèle optimisé dans RegressorChain\n",
    "chain_rf = RegressorChain(best_rf)\n",
    "chain_rf.fit(X_train, y_train)\n",
    "y_pred_chain = chain_rf.predict(X_test)\n",
    "\n",
    "# Séparation des prédictions de retard_moyen_arrivee\n",
    "y_pred_retard = y_pred_chain[:, 0]\n",
    "\n",
    "# Prédictions pour les autres colonnes\n",
    "y_pred_cause = y_pred_chain[:, 1:]\n",
    "\n",
    "# Normalisation de ces prédictions pour qu'elles somment à 100\n",
    "sums = y_pred_cause.sum(axis=1)[:, np.newaxis]\n",
    "y_pred_normalized = 100 * y_pred_cause / sums\n",
    "\n",
    "# Ajout des prédictions de retard_moyen_arrivee aux prédictions normalisées\n",
    "y_pred_final = np.hstack([y_pred_retard[:, np.newaxis], y_pred_normalized])\n",
    "\n",
    "for i, cible in enumerate(cibles):\n",
    "    mae = mean_absolute_error(y_test[cible], y_pred_final[:, i])\n",
    "    mse_randomized = mean_squared_error(y_test[cible], y_pred_final[:, i])\n",
    "    mape = mean_absolute_percentage_error(y_test[cible], y_pred_final[:, i])\n",
    "    r2 = r2_score(y_test[cible], y_pred_final[:, i])\n",
    "    \n",
    "    print(f\"--- {cible} ---\")\n",
    "    print(f\"Mean Squared Error with RandomizedSearch: {mse_randomized}\")\n",
    "    print(f\"Mean Absolute Error with RandomizedSearch: {mae}\")\n",
    "    print(f\"Mean Absolute Percentage Error with RandomizedSearch: {mape}\")\n",
    "    print(f\"R2 Score with RandomizedSearch: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Regressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# Initialisation de l'estimateur AdaBoost\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "# Grille d'hyperparamètres pour AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "# Utilisation de RandomizedSearchCV pour optimiser les hyperparamètres\n",
    "ada_search = RandomizedSearchCV(ada, param_distributions=param_grid_ada, n_iter=100, cv=5, verbose=0, n_jobs=-1, random_state=42)\n",
    "ada_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs hyperparamètres pour AdaBoost\n",
    "print(ada_search.best_params_)\n",
    "\n",
    "# Prédiction avec le modèle AdaBoost optimisé\n",
    "y_pred_ada = ada_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Métriques d'évaluation pour AdaBoost\n",
    "mae_ada = mean_absolute_error(y_test, y_pred_ada)\n",
    "mse_ada = mean_squared_error(y_test, y_pred_ada)\n",
    "mape_ada = mean_absolute_percentage_error(y_test, y_pred_ada)\n",
    "r2_ada = r2_score(y_test, y_pred_ada)\n",
    "\n",
    "print(f\"Mean Squared Error with AdaBoost: {mse_ada}\")\n",
    "print(f\"Mean Absolute Error with AdaBoost: {mae_ada}\")\n",
    "print(f\"Mean Absolute Percentage Error with AdaBoost: {mape_ada}\")\n",
    "print(f\"R2 Score with AdaBoost: {r2_ada}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanivbenchetrit/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       ligne  cluster\n",
      "0        BORDEAUX ST JEAN-PARIS MONTPARNASSE        1\n",
      "1       LA ROCHELLE VILLE-PARIS MONTPARNASSE        2\n",
      "2                 PARIS MONTPARNASSE-QUIMPER        2\n",
      "3                 PARIS MONTPARNASSE-ST MALO        0\n",
      "4     PARIS MONTPARNASSE-ST PIERRE DES CORPS        2\n",
      "...                                      ...      ...\n",
      "8149                    STRASBOURG-PARIS EST        1\n",
      "8150    TOULOUSE MATABIAU-PARIS MONTPARNASSE        0\n",
      "8151                TOURS-PARIS MONTPARNASSE        2\n",
      "8152           VALENCE ALIXAN TGV-PARIS LYON        1\n",
      "8153               VANNES-PARIS MONTPARNASSE        2\n",
      "\n",
      "[8154 rows x 2 columns]\n",
      "0       1\n",
      "1       2\n",
      "2       2\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "8149    1\n",
      "8150    0\n",
      "8151    2\n",
      "8152    2\n",
      "8153    2\n",
      "Name: majority_class, Length: 8154, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "k_optimal = 3\n",
    "kmeans = KMeans(n_clusters=k_optimal, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "print(df[['ligne', 'cluster']])\n",
    "\n",
    "\n",
    "\n",
    "majority_class = {}\n",
    "lignes= df['ligne'].unique()\n",
    "for ligne in lignes:\n",
    "    cluster_labels = df[df['ligne'] == ligne]['cluster'].tolist()\n",
    "    majority_label = Counter(cluster_labels).most_common(1)[0][0]\n",
    "    majority_class[ligne] = majority_label\n",
    "\n",
    "\n",
    "df['majority_class'] = df['ligne'].map(majority_class)\n",
    "\n",
    "X['majority_class'] = df['majority_class']\n",
    "\n",
    "print(X['majority_class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5647cfce6fa2861c5d5993eed494c4303d5a706b1125d41555b49a965ed01245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
